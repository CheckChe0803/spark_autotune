spark.app.name Spark-2.3.x
spark.driver.memory 1g
spark.executor.memory 2g
spark.extraListeners org.apache.spark.listeners.BytedanceSparkListener
spark.submit.deployMode client
spark.scheduler.listenerbus.eventqueue.size 150000

spark.executor.extraJavaOptions  -XX:+UseG1GC -XX:-UseGCOverheadLimit -verbose:gc -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark 

spark.shuffle.consolidateFiles true
spark.shuffle.service.enabled true

spark.eventLog.enabled true
spark.eventLog.dir hdfs://haruna/spark/history
spark.eventLog.internal.dir    hdfs://haruna/spark/history
spark.yarn.stagingDir hdfs://haruna/spark/stage_new


spark.serializer org.apache.spark.serializer.KryoSerializer

spark.executor.cores 4
spark.executor.logs.rolling.maxRetainedFiles 10
spark.executor.logs.rolling.strategy time
spark.executor.logs.rolling.time.interval daily



spark.port.maxRetries 100
spark.worker.timeout 900
spark.core.connection.auth.wait.timeout 450


# Scheduling
spark.task.maxFailures 8
spark.dynamicAllocation.enabled true
spark.dynamicAllocation.initialExecutors 5
spark.dynamicAllocation.minExecutors 5
spark.dynamicAllocation.maxExecutors 30

# spark.blacklist.enabled true


# Spark History
spark.history.fs.update.interval 10
spark.history.retainedApplications 30
spark.history.ui.port 18080
spark.history.ui.maxApplications 3500
spark.yarn.historyServer.address 10.8.136.132:18080
spark.history.fs.cleaner.enabled false


# Spark Streaming
spark.streaming.blockInterval 200
spark.streaming.kafka.maxRetries 4


# Yarn
spark.yarn.submit.file.replication 3
spark.yarn.preserve.staging.files false
spark.yarn.scheduler.heartbeat.interval-ms 7500

# Hive
spark.sql.hive.verifyPartitionPath false
spark.sql.hive.metastorePartitionPruning true
spark.sql.optimizer.metadataOnly true
spark.sql.parquet.filterPushdown true
spark.sql.hive.convertMetastoreParquet true
spark.sql.hive.caseSensitiveInferenceMode NEVER_INFER
spark.sql.orc.impl native
spark.sql.hive.convertMetastoreOrc true

# Spark GDPR permission validation
spark.sql.hive.gdpr.enable true
spark.sql.hive.gdpr.security.center.psm data.olap.tqs_analysis_cn
spark.sql.hive.gdpr.userNoAuth.validation true
spark.sql.hive.gdpr.tqs.network.timeout 30000
spark.sql.hive.audit.app.name hive

# Self defined
spark.locality.ignore true

#region
spark.region cn
spark.region.defaultCluster default

# Hdfs
spark.hadoop.dfs.client.hedged.read.within.dc.threshold.millis 100
spark.hadoop.dfs.client.hedged.read.cross.dc.threshold.millis 200
spark.hadoop.dfs.client.block.write.retries 10
